{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ruben\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['USE_PYGEOS'] = '0'\n",
    "import geopandas as gpd\n",
    "import momepy as mm\n",
    "import networkx as nx\n",
    "from shapely import Point, LineString, reverse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from pyproj import Transformer\n",
    "import datetime"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. LECTURA DELS NODES I DELS ARCS. CREACIÓ DEL GRAF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La xarxa OPERATIVA completa conte: \n",
      "nodes =  13572\n",
      "arcs = 13682\n"
     ]
    }
   ],
   "source": [
    "# Introduim la xarxa completa en un Graph de NetworkX\n",
    "node = gpd.read_file(\"data/networks/AdG_node.gpkg\")\n",
    "arc = gpd.read_file(\"data/networks/AdG_arc.gpkg\")\n",
    "\n",
    "\n",
    "G0 = nx.DiGraph()\n",
    "G0.add_nodes_from([(row['node_id'], row) for index, row in node.iterrows() if row['state']!=0])\n",
    "G0.add_edges_from([(row['node_1'], row['node_2'], row) for index, row in arc.iterrows() if row['state']!=0])\n",
    "# estem eliminant els obsolets escollint nomes els state=0 (OPERATIVO)\n",
    "\n",
    "print('La xarxa OPERATIVA completa conte: ')\n",
    "print('nodes = ', len(G0.nodes))\n",
    "print('arcs =', len(G0.edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La xarxa OPERATIVA completa conte: \n",
      "nodes =  13572\n",
      "arcs = 13682\n"
     ]
    }
   ],
   "source": [
    "# Read node data from CSV file\n",
    "node_data = pd.read_csv(\"data/node2021.csv\")\n",
    "\n",
    "# Create a dictionary to convert the node data to a format that can be used with NetworkX\n",
    "node_dict = {}\n",
    "for index, row in node_data.iterrows():\n",
    "    if row['state'] != 0: # Check if the node is not obsolete\n",
    "        node_id = row['node_id']\n",
    "        node_data = row.to_dict()\n",
    "        node_dict[node_id] = node_data\n",
    "\n",
    "# Read edge data from CSV file\n",
    "edge_data = pd.read_csv(\"data/arc2021.csv\")\n",
    "\n",
    "# Create a list of tuples containing the edge data\n",
    "edge_list = []\n",
    "for index, row in edge_data.iterrows():\n",
    "    if row['state'] != 0: # Check if the edge is not obsolete\n",
    "        node_1 = row['node_1']\n",
    "        node_2 = row['node_2']\n",
    "        edge_data = row.to_dict()\n",
    "        edge_list.append((node_1, node_2, edge_data))\n",
    "\n",
    "# Create a NetworkX graph and add the nodes and edges\n",
    "G21 = nx.DiGraph()\n",
    "G21.add_nodes_from(node_dict.items())\n",
    "G21.add_edges_from(edge_list)\n",
    "\n",
    "print('La xarxa OPERATIVA completa conte: ')\n",
    "print('nodes = ', len(G21.nodes))\n",
    "print('arcs =', len(G21.edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ruben\\AppData\\Local\\Temp\\ipykernel_15992\\3617289775.py:13: DtypeWarning: Columns (63) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  edge_data = pd.read_csv(\"data/arc2023.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La xarxa OPERATIVA completa conte: \n",
      "nodes =  13608\n",
      "arcs = 13720\n"
     ]
    }
   ],
   "source": [
    "# Read node data from CSV file\n",
    "node_data = pd.read_csv(\"data/node2023.csv\")\n",
    "\n",
    "# Create a dictionary to convert the node data to a format that can be used with NetworkX\n",
    "node_dict = {}\n",
    "for index, row in node_data.iterrows():\n",
    "    if row['state'] != 0: # Check if the node is not obsolete\n",
    "        node_id = row['node_id']\n",
    "        node_data = row.to_dict()\n",
    "        node_dict[node_id] = node_data\n",
    "\n",
    "# Read edge data from CSV file\n",
    "edge_data = pd.read_csv(\"data/arc2023.csv\")\n",
    "\n",
    "# Create a list of tuples containing the edge data\n",
    "edge_list = []\n",
    "for index, row in edge_data.iterrows():\n",
    "    if row['state'] != 0: # Check if the edge is not obsolete\n",
    "        node_1 = row['node_1']\n",
    "        node_2 = row['node_2']\n",
    "        edge_data = row.to_dict()\n",
    "        edge_list.append((node_1, node_2, edge_data))\n",
    "\n",
    "# Create a NetworkX graph and add the nodes and edges\n",
    "G23 = nx.DiGraph()\n",
    "G23.add_nodes_from(node_dict.items())\n",
    "G23.add_edges_from(edge_list)\n",
    "\n",
    "print('La xarxa OPERATIVA completa conte: ')\n",
    "print('nodes = ', len(G23.nodes))\n",
    "print('arcs =', len(G23.edges))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ens inventem els codis d'aquells que no en tenen un de correcte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_amb_codi_erroni =([node for node, data in G.nodes(data=True) if data['code'][0:2] != 'PR'])\n",
    "\n",
    "i = 0\n",
    "for node in nodes_amb_codi_erroni:\n",
    "  data = G.nodes[node]\n",
    "  data['code'] = 'DESC' + str(i)\n",
    "  i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes_amb_codi_erroni pel 2021 = 2334\n",
      "nodes_amb_codi_erroni pel 2023 - 2346\n"
     ]
    }
   ],
   "source": [
    "nodes_amb_codi_erroni_21 =([node for node, data in G21.nodes(data=True) if data['code'][0:2] != 'PR'])\n",
    "nodes_amb_codi_erroni_23 =([node for node, data in G23.nodes(data=True) if data['code'][0:2] != 'PR'])\n",
    "print('nodes_amb_codi_erroni pel 2021 =', len(nodes_amb_codi_erroni_21) )\n",
    "print('nodes_amb_codi_erroni pel 2023 -', len(nodes_amb_codi_erroni_23) )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. CREACIÓ DEL SUBGRAF QUE CONTÉ LA DEPURADORA\n",
    "\n",
    "Definim un subGraph com la xarxa connectada a la depuradora.\n",
    "\n",
    "no hi ha cap node/arc desconectat en el subGraph\n",
    "\n",
    "estem extraien tambe els sistemes de drenatge urba no connectats a la xarxa residual. \n",
    "\n",
    "suposem que no existeixen nodes sanitaris fora d'aquesta xarxa (cal comprovar).\n",
    "\n",
    "obenim una xarxa perfectament connectada.\n",
    "\n",
    "També es detecta els nodes que no tenen sortida i no són un outfall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La xarxa connectada a la depuradora conte: \n",
      "nodes =  12017\n",
      "arcs = 12516\n",
      "---\n",
      "nodes OUTFALL = 128\n",
      "nodes CHAMBER-NETINIT = 15\n",
      "nodes tipo sink = 37\n",
      "arcs sobreeixidor = 277\n"
     ]
    }
   ],
   "source": [
    "#Extraiem la sub-xarxa connectada a la depuradora\n",
    "#Definim la depuradora\n",
    "\n",
    "G=G21\n",
    "edar_code= 'PR0005300'\n",
    "edar=[node for node, data in G.nodes(data=True) if data['code'] == edar_code][0]\n",
    "\n",
    "# definim el subGraph associat:\n",
    "G_notDi = nx.Graph(G)\n",
    "subGraph = nx.DiGraph(nx.subgraph(G,nx.node_connected_component(G_notDi, edar)))\n",
    "\n",
    "print('La xarxa connectada a la depuradora conte: ')\n",
    "print( 'nodes = ', len(subGraph.nodes))\n",
    "print('arcs =', len(subGraph.edges))\n",
    "print('---')\n",
    "\n",
    "\n",
    "# nodes marcats com OUTFALL\n",
    "outfalls= [node for node, data in subGraph.nodes(data=True) if data['epa_type'] == 'OUTFALL']\n",
    "print('nodes OUTFALL =', len(outfalls))\n",
    "\n",
    "# nodes marcats com CHAMBERS\n",
    "chambers_netinit= [node for node, data in subGraph.nodes(data=True) if data['nodecat_id'] == 'CEC' and subGraph.degree(node)==1]\n",
    "print('nodes CHAMBER-NETINIT =', len(chambers_netinit))\n",
    "\n",
    "# detectem els nodes tipo sink del subGraph\n",
    "sink = {node: data for node, data in subGraph.nodes(data=True) if subGraph.out_degree(node) == 0 and node!=edar and data['epa_type'] != 'OUTFALL'}\n",
    "print('nodes tipo sink =', len(sink))\n",
    "\n",
    "# arcs marcats com Sobreeixidor\n",
    "sobreeixidors = [(node1, node2) for node1, node2, data in subGraph.edges(data=True) if data['category_type'] == 'Sobreeixidor']\n",
    "print('arcs sobreeixidor =', len(sobreeixidors))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11495,\n",
       " 12305,\n",
       " 12818,\n",
       " 14941,\n",
       " 15596,\n",
       " 17563,\n",
       " 1896,\n",
       " 2109,\n",
       " 42936,\n",
       " 4869,\n",
       " 5162,\n",
       " 7387,\n",
       " 7826,\n",
       " 8267,\n",
       " 9452]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chambers_netinit"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revisem els nodes sinks i eliminem aquells que no son Chambers. S'eliminen alguns que son bons (2003, 33882, 34892, 6242, 9589, node_id d'adg21), pero la majoria no tenen cap informacio.\n",
    "\n",
    "No afecten gaire al resultat perque son nodes inici de red que creiem que tenen l'aresta girada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La xarxa connectada a la depuradora conte: \n",
      "nodes =  11986\n",
      "arcs = 12485\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "bad_sink = [key for key, value in sink.items() if subGraph.degree(key) == 1 and value['nodecat_id'] !='CEC']\n",
    "\n",
    "subGraph.remove_nodes_from(bad_sink)\n",
    "print('La xarxa connectada a la depuradora conte: ')\n",
    "print( 'nodes = ', len(subGraph.nodes))\n",
    "print('arcs =', len(subGraph.edges))\n",
    "print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3670, 12220, 12818, 30191, 45423, 51236}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(sink) - set(bad_sink)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "860"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_llegan_depuradora = [node for node in subGraph.nodes if not nx.has_path(subGraph, node, edar)]\n",
    "len(no_llegan_depuradora)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "direccions\n",
    "1. sub-xarxa connectada a la depuradora : subGraph\n",
    "2. sink: inicis de xarxa incorrectes, corregir direccions. report changes\n",
    "3. comprovar direccions edge: tots aquells arcs que no son sistemes de sobreiximent, han danar direxionats a la depuradora.\n",
    "\n",
    "\n",
    "nodes\n",
    "1.1 alguns nodes tenen code incorrecte, comunicar reportar casos, mantenim el node_id de adg code=PRdnode_id\n",
    "1.2 top_elev: corregir nan amb z, comprovar valors fora del rang esperat z-1 < top_elev < z+1\n",
    "   colocar valors a custom_top_elev\n",
    "1.3 ymax: corregim nan amb '1'. colocar canvis a custom_ymax\n",
    "1.4 matcat_id if null write DESC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 corregim el code dels nodes amb identificadoe incorrectes\n",
    "\n",
    "nodes_amb_codi_erroni =([node for node, data in subGraph.nodes(data=True) if data['code'][0:2] != 'PR'])\n",
    "\n",
    "i = 0\n",
    "for node in nodes_amb_codi_erroni:\n",
    "  data = subGraph.nodes[node]\n",
    "  data['code'] = 'PRd' + str(data['node_id'] )\n",
    "  i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in subGraph.nodes(data=True):\n",
    "    if row['state'] != 0:\n",
    "        x = row['geometry'].x\n",
    "        y = row['geometry'].y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes_amb_top_elev_empt =  8267\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'geometry'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ruben\\Dropbox\\Girona\\GiroNat-main\\GiroNat-main\\xarxa.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ruben/Dropbox/Girona/GiroNat-main/GiroNat-main/xarxa.ipynb#X46sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mfor\u001b[39;00m node \u001b[39min\u001b[39;00m nodes_amb_top_elev_empty:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ruben/Dropbox/Girona/GiroNat-main/GiroNat-main/xarxa.ipynb#X46sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m   data \u001b[39m=\u001b[39m G\u001b[39m.\u001b[39mnodes[node]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/ruben/Dropbox/Girona/GiroNat-main/GiroNat-main/xarxa.ipynb#X46sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m   data[\u001b[39m'\u001b[39m\u001b[39mcustom_top_elev\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m data[\u001b[39m'\u001b[39;49m\u001b[39mgeometry\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39m\u001b[39mz\u001b[39m\u001b[39m'\u001b[39m]   \u001b[39m#??\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ruben/Dropbox/Girona/GiroNat-main/GiroNat-main/xarxa.ipynb#X46sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m   i \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ruben/Dropbox/Girona/GiroNat-main/GiroNat-main/xarxa.ipynb#X46sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mdespres de corregir...\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'geometry'"
     ]
    }
   ],
   "source": [
    "# 1.2 corregim top_elev\n",
    "#utilitzem el graph G:\n",
    "G=G21\n",
    "\n",
    "\n",
    "# per als <0 (NULL included)\n",
    "nodes_amb_top_elev_empty =([node for node, data in G.nodes(data=True) if float(data['top_elev']) >= 0])\n",
    "print('nodes_amb_top_elev_empt = ', len(nodes_amb_top_elev_empty))\n",
    "\n",
    "#corregim els valors a custom_top_elev\n",
    "i = 0\n",
    "for node in nodes_amb_top_elev_empty:\n",
    "  data = G.nodes[node]\n",
    "  data['custom_top_elev'] = data['geometry'].z   #com puc accedir a la z ??\n",
    "  i += 1\n",
    "\n",
    "print('despres de corregir...')\n",
    "nodes_amb_top_elev_empty =([node for node, data in G.nodes(data=True) if (float(data['top_elev']) >= 0 or float(data['custom_top_elev']) >= 0) ]  )\n",
    "print('nodes_amb_top_elev_empt = ',len(nodes_amb_top_elev_empty))\n",
    "  \n",
    "\n",
    "\n",
    "# comprovem que top_elev es trpba en el rang esperat z-1<top_elev<z+1\n",
    "masc_top_elev=  (float(row['geometry'].z)-1) < float(data['top_elev']) < (float(row['geometry'].z)+1)\n",
    "nodes_amb_top_elev_erroni =([node for node, data in G.nodes(data=True) if masc_top_elev])\n",
    "\n",
    "\n",
    "#print(len(nodes_amb_top_elev_erroni))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "my_node=[node for node, data in G21.nodes(data=True) if data['node_id'] == '39079']\n",
    "print(my_node)\n",
    "\n",
    "my_arc=[(node1, node2) for node1, node2, data in subGraph.edges(data=True) if data['arc_id'] == '2362']\n",
    "#print(my_arc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nodes\n",
    "\n",
    "1. top_elev: corregir nan amb z, comprovar valors fora del rang esperat z-1 < top_elev < z+1\n",
    "   colocar valors a custom_top_elev\n",
    "2. ymax: corregim nan amb '1'. colocar canvis a custom_ymax\n",
    "4. matcat_id if null write DESC\n",
    "\n",
    "nota: alguns nodes tenen code incorrecte, comunicar reportar casos, mantenim el node_id de adg code=PRDnode_id"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "arcs\n",
    "\n",
    "1. comprovar node_1/2, alguns valors em surten null* a les taules, com pot ser?\n",
    "2. comprovar null* en nodetype_1/2\n",
    "3. y1: comprovar valors fora del rang esperat (0,10), corregir valor superiors a 10 , if nan* posar y1=ymax(node1)\n",
    "*giswater hauria de corregir els nan si corregim els ymax dels nodes\n",
    "   comprovar que: ymax(node1)-1 < y1 < ymax(node1)+1\n",
    "   colocar valors corregits a costum_y1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. CORRECCIÓ DE LES DIRECCIONS\n",
    "\n",
    "definim node de \"sobreximent\" com nodes direccionats cap a un node que no es la depuradura\n",
    "    \n",
    "volem que els nodes de sobreiximent detectats coiniceixin amb els catalogats com a outfall o chamber-netinit \n",
    "\n",
    "considerem errors de diseny les diferencies -> corregim\n",
    "\n",
    "#TODO afegir tambe aquelles chambers sense predecesor (netinit) a la llista de permesos\n",
    "    \n",
    "#TODO imprimir llista de diferencies per comunicar a AdG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes que no arriben a la depuradora = 860\n",
      "nodes que no arriben a la depuradora ni a un outfall ni a un chamber = 38\n",
      "nodes que no arriben a la depuradora després del direccionament = 822\n",
      "nodes que no arriben a la depuradora ni a un outfall després del direccionament = 1\n"
     ]
    }
   ],
   "source": [
    "# TODO: problemes amb els nodes tipus \"CHAMBER\" i \"STORAGE\". Crear un nou arc?\n",
    "# S'intercanvien els valors del node 1 i node 2 de l'aresta\n",
    "# \n",
    "attributes = ['node_', 'y', 'custom_y', 'elev', 'custom_elev', 'sys_elev', 'nodetype_', 'sys_y', 'r', 'z']\n",
    "        \n",
    "def intercambiarValores(data):\n",
    "  \n",
    "  for attribute in attributes:\n",
    "    if attribute+'1' in data:\n",
    "      aux = data[attribute+'1']\n",
    "      data[attribute+'1'] = data[attribute+'2']\n",
    "      data[attribute+'2'] = aux\n",
    "    \n",
    "  if 'geometry' in data:\n",
    "    data['geometry'] = reverse(data['geometry'])\n",
    "  \n",
    "  return data\n",
    "\n",
    "\n",
    "# Per direccionar els arcs del subGraph que no arriben a la depuradora o als nodes de sobreiximent\n",
    "# 1. Trobem tots els nodes que no arriben a la depuradora\n",
    "# 2. Trobem els nodes del punt 1 que no arriben a cap outfall\n",
    "no_llegan_depuradora = [node for node in subGraph.nodes if not nx.has_path(subGraph, node, edar)]\n",
    "\n",
    "no_llegan_outfall = []\n",
    "for node in no_llegan_depuradora:\n",
    "    outfalls_i_chambers = outfalls + chambers_netinit\n",
    "    if node not in outfalls_i_chambers :\n",
    "      llega = False\n",
    "      i = 0\n",
    "      while not llega and len(outfalls_i_chambers)>i:\n",
    "        llega = nx.has_path(subGraph, node, outfalls_i_chambers[i])\n",
    "        i += 1\n",
    "      if not llega:\n",
    "        no_llegan_outfall.append(node)\n",
    "\n",
    "print('nodes que no arriben a la depuradora =', len(no_llegan_depuradora))\n",
    "print('nodes que no arriben a la depuradora ni a un outfall ni a un chamber =', len(no_llegan_outfall))\n",
    "\n",
    "malament = no_llegan_outfall.copy()\n",
    "\n",
    "# 3. Mentre hi hagi nodes que no arribin a la depuradora ni a un outfall\n",
    "# 3.1 Per tots aquests nodes\n",
    "# 3.1.1 Mirem si els seus veins arriben a la depuradora\n",
    "# 3.1.2 Si algun vei arriba a la depuradora, afegim un nou arc que va del node al vei i eliminem l'antic\n",
    "# 3.2 Si cap dels seus veins arriba a la depuradora, s'afegeix de nou a la llista  de nodes a revisar\n",
    "arcs_girats = []\n",
    "while len(no_llegan_outfall)>0:\n",
    "  no = []\n",
    "  for node in no_llegan_outfall:\n",
    "    teCami = nx.has_path(subGraph, node, edar)\n",
    "    if not teCami:\n",
    "      veins = list(nx.all_neighbors(subGraph, node))\n",
    "    while not teCami and len(veins)>0:\n",
    "      v = veins.pop()\n",
    "      teCami = nx.has_path(subGraph, v, edar)\n",
    "      if teCami and subGraph.has_edge(v,node):\n",
    "        data = intercambiarValores(subGraph.get_edge_data(v, node))\n",
    "        data['girada'] = True\n",
    "        subGraph.add_edge(node, v, **data)\n",
    "        subGraph.remove_edge(v, node)\n",
    "        arcs_girats.append(data['code'])\n",
    "    if not teCami:\n",
    "      no.append(node)\n",
    "  no_llegan_outfall = no\n",
    "  \n",
    "# Si tornem a veure els nodes que no arriben a la depuradora, no haurien de quedar cap\n",
    "\n",
    "no_llegan_depuradora_arreglat = [node for node in subGraph.nodes if not nx.has_path(subGraph, node, edar)]\n",
    "\n",
    "no_llegan_outfall_arreglat = []\n",
    "for node in no_llegan_depuradora_arreglat:\n",
    "    if node not in outfalls:\n",
    "      llega = False\n",
    "      i = 0\n",
    "      while not llega and len(outfalls)>i:\n",
    "        llega = nx.has_path(subGraph, node, outfalls[i])\n",
    "        i += 1\n",
    "      if not llega:\n",
    "        no_llegan_outfall_arreglat.append(node)\n",
    "        \n",
    "print('nodes que no arriben a la depuradora després del direccionament =', len(no_llegan_depuradora_arreglat))\n",
    "print('nodes que no arriben a la depuradora ni a un outfall després del direccionament =', len(no_llegan_outfall_arreglat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12818]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_llegan_outfall_arreglat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'arc_id': 12217,\n",
       " 'code': 'TR0023709',\n",
       " 'node_1': 12220.0,\n",
       " 'node_2': 12216.0,\n",
       " 'y1': nan,\n",
       " 'y2': nan,\n",
       " 'elev1': nan,\n",
       " 'elev2': nan,\n",
       " 'custom_y1': nan,\n",
       " 'custom_y2': nan,\n",
       " 'custom_elev1': nan,\n",
       " 'custom_elev2': nan,\n",
       " 'sys_elev1': nan,\n",
       " 'sys_elev2': nan,\n",
       " 'arc_type': 'TRAM',\n",
       " 'arccat_id': 'PVC160-CC',\n",
       " 'matcat_id': nan,\n",
       " 'epa_type': 'CONDUIT',\n",
       " 'sector_id': 1,\n",
       " 'state': 1,\n",
       " 'state_type': 2,\n",
       " 'annotation': 'SE15_75',\n",
       " 'observ': 'PRIVAT-TRAM RECULL ESC.-O. ESTUDI GIRONA',\n",
       " 'comment': nan,\n",
       " 'sys_slope': nan,\n",
       " 'inverted_slope': nan,\n",
       " 'custom_length': nan,\n",
       " 'dma_id': 0,\n",
       " 'soilcat_id': nan,\n",
       " 'function_type': 'Altres',\n",
       " 'category_type': nan,\n",
       " 'fluid_type': 'UNITARIES',\n",
       " 'location_type': nan,\n",
       " 'workcat_id': nan,\n",
       " 'workcat_id_end': nan,\n",
       " 'buildercat_id': nan,\n",
       " 'builtdate': nan,\n",
       " 'enddate': nan,\n",
       " 'ownercat_id': 'ALTRES',\n",
       " 'muni_id': 1,\n",
       " 'postcode': nan,\n",
       " 'streetaxis_id': nan,\n",
       " 'postnumber': nan,\n",
       " 'postcomplement': nan,\n",
       " 'streetaxis2_id': nan,\n",
       " 'postnumber2': nan,\n",
       " 'postcomplement2': nan,\n",
       " 'descript': nan,\n",
       " 'link': nan,\n",
       " 'verified': nan,\n",
       " 'the_geom': '0102000020E7640000020000006AE5CBE292A21D4176A27380AAB851419EE971914BA21D41D7901718AAB85141',\n",
       " 'undelete': nan,\n",
       " 'label_x': nan,\n",
       " 'label_y': nan,\n",
       " 'label_rotation': nan,\n",
       " 'publish': True,\n",
       " 'inventory': False,\n",
       " 'uncertain': False,\n",
       " 'expl_id': 1,\n",
       " 'num_value': nan,\n",
       " 'feature_type': 'ARC',\n",
       " 'tstamp': '2021-06-23 14:02:22.343713',\n",
       " 'lastupdate': '2011-05-13 00:00:00',\n",
       " 'lastupdate_user': nan,\n",
       " 'insert_user': 'postgres',\n",
       " 'district_id': nan,\n",
       " 'workcat_id_plan': nan}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subGraph.get_edge_data(v, node)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprovem quants nodes tenen valors nulls a top_elev o un top_elev>300.\n",
    "Una vegada els tenim, corretgim les altures amb el valor del seu successor.\n",
    "Primer, posem tots els valors que creiem que estan be de top_elev a costum_top_elev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes_erronis incials 4382\n",
      "nodes_erronis a iteracio 1 :  1624\n",
      "nodes_erronis a iteracio 2 :  886\n",
      "nodes_erronis a iteracio 3 :  489\n",
      "nodes_erronis a iteracio 4 :  277\n",
      "nodes_erronis a iteracio 5 :  153\n",
      "nodes_erronis a iteracio 6 :  90\n",
      "nodes_erronis a iteracio 7 :  54\n",
      "nodes_erronis a iteracio 8 :  32\n",
      "nodes_erronis a iteracio 9 :  14\n",
      "nodes_erronis a iteracio 10 :  4\n",
      "nodes_erronis a iteracio 11 :  1\n",
      "nodes_erronis a iteracio 12 :  0\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "nodes_erronis = []\n",
    "\n",
    "for node, data in subGraph.nodes(data=True):\n",
    "    if not math.isnan(data['top_elev']) and not data['top_elev']>300:\n",
    "        data['custom_top_elev'] = data['top_elev']\n",
    "    else: \n",
    "        data['custom_top_elev'] = math.nan\n",
    "        nodes_erronis.append(node)\n",
    "print('nodes_erronis incials', len(nodes_erronis))\n",
    "\n",
    "\n",
    "i = 0\n",
    "while len(nodes_erronis) > 0:\n",
    "    tmp = []\n",
    "    for node_erroni in nodes_erronis:\n",
    "        data_err = subGraph.nodes[node_erroni]\n",
    "        neighbors = list(nx.all_neighbors(subGraph, node_erroni))\n",
    "        costums_top_elev_neighbors = [data['custom_top_elev'] for node, data in subGraph.nodes(data=True) if node in neighbors and not math.isnan(data['custom_top_elev'])]\n",
    "        if len(costums_top_elev_neighbors) > 0:\n",
    "            data_err['custom_top_elev'] = np.mean(costums_top_elev_neighbors)\n",
    "        else:\n",
    "            tmp.append(node_erroni)\n",
    "    i+=1\n",
    "    nodes_erronis = tmp.copy()\n",
    "    print('nodes_erronis a iteracio', i, ': ', len(nodes_erronis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2958"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_top_elev_erronis = [node for node, data in subGraph.nodes(data=True) if math.isnan(data['ymax']) or data['ymax']<0.25]\n",
    "len(nodes_top_elev_erronis)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 GENERACIÓ DEL REPORT\n",
    "\n",
    "Hi ha errors amb el code de molts nodes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"results/reports/AdG.txt\", \"w\")\n",
    "f.write(\"El llistat de nodes que no arriben a la depuradora és el següent:\\n\")\n",
    "for node in malament:\n",
    "  id = subGraph.nodes[node]['code']\n",
    "  if id[0:2] == 'PR':\n",
    "    if node != malament[-1]:\n",
    "      f.write(str(subGraph.nodes[node]['code'])+\", \")\n",
    "    else:\n",
    "      f.write(str(subGraph.nodes[node]['code'])+\".\")\n",
    "  else:\n",
    "    if node != malament[-1]:\n",
    "      f.write(str(subGraph.nodes[node]['node_id'])+\", \")\n",
    "    else:\n",
    "      f.write(str(subGraph.nodes[node]['node_id'])+\".\")\n",
    "f.write(\"\\n\\nPer arreglar-los s'han canviat les direccions dels arcs següents:\\n\")\n",
    "for arc in arcs_girats:\n",
    "  if arc != arcs_girats[-1]:\n",
    "    f.write(str(arc)+\", \")\n",
    "  else:\n",
    "    f.write(str(arc)+\".\")\n",
    "f.close()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. S'ELIMINEN ELS OUTFALLS I ELS NODES QUE ARRIBEN A ELLS DEL SUBGRAF\n",
    "\n",
    "Posar threshold en els nodes de sobreiximent per construir xarxa en sec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes que no arriben a la depuradora després d'eliminar els nodes de sobreiximent = 0\n",
      "La subxarxa en que tots els nodes arriben a la depuradora conte: \n",
      "nodes =  11196\n",
      "arcs = 11680\n"
     ]
    }
   ],
   "source": [
    "#volem extreure els node outfall de sobreiximent i els seus predecesors del subGrap\n",
    "delete = [node for node, data in subGraph.nodes(data=True) if not nx.has_path(subGraph, node, edar)]\n",
    "subGraph.remove_nodes_from(delete)\n",
    "# nota: estem extraient els nodes direccionats com a desembocament del subGrap exceptuant la depuradora hauria de ser el mateixos que els marcats com a outfall\n",
    "\n",
    "# Si tornem a veure els nodes que no arriben a la depuradora, no haurien de quedar cap\n",
    "no_llegan_depuradora_arreglat = [node for node in subGraph.nodes if not nx.has_path(subGraph, node, edar)]\n",
    "        \n",
    "print('nodes que no arriben a la depuradora després d\\'eliminar els nodes de sobreiximent =', len(no_llegan_depuradora_arreglat))\n",
    "\n",
    "print('La subxarxa en que tots els nodes arriben a la depuradora conte: ')\n",
    "print('nodes = ', len(subGraph.nodes))\n",
    "print('arcs =', len(subGraph.edges))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. IMPRIMIR EL SUBGRAF CONNECTAT A LA DEPURADORA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sergi/.local/lib/python3.10/site-packages/momepy/utils.py:430: UserWarning: Approach is not set. Defaulting to 'primal'.\n",
      "  warnings.warn(\"Approach is not set. Defaulting to 'primal'.\")\n"
     ]
    }
   ],
   "source": [
    "#imprimim el graph en un .gpkg per visualitzar en QGIS\n",
    "\n",
    "#transformem les coordenades\n",
    "transformer = Transformer.from_crs(\"EPSG:25831\", \"WGS84\")\n",
    "\n",
    "#afegim els nodes\n",
    "for index, row in subGraph.nodes(data=True):\n",
    "    if row['state'] != 0:\n",
    "        x = row['geometry'].x\n",
    "        y = row['geometry'].y\n",
    "\n",
    "        long, lat = transformer.transform(x, y)\n",
    "        row['longitude'] = long\n",
    "        row['latitude'] = lat\n",
    "        row['x'] = x\n",
    "        row['y'] = y\n",
    "        \n",
    "        row['geometry'] = (long, lat)    \n",
    "\n",
    "# fem una copia del subgraph i el reindexem amb la geometria dels nodes\n",
    "subGraph_copy = subGraph.copy()\n",
    "geometry_nodes = {node: data['geometry'] for node, data in subGraph_copy.nodes(data=True)}\n",
    "subGraph_copy = nx.relabel_nodes(subGraph_copy, geometry_nodes)\n",
    "\n",
    "# guardem el subgraph en dos .gpkg, un per nodes i un per arcs\n",
    "points, lines = mm.nx_to_gdf(subGraph_copy)\n",
    "points.set_geometry(\"geometry\")\n",
    "points.to_file(\"results/networks/nodes_corretgits.gpkg\", layer='nodes', driver=\"GPKG\")\n",
    "lines.set_geometry(\"geometry\")\n",
    "lines.to_file(\"results/networks/arcs_corretgits.gpkg\", layer='arcs', driver=\"GPKG\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. correccio links\n",
    "\n",
    "1. Els nodes y arcs del subGraph tenen links associats que porten a guilly y connec (features_type -> defineix la llista on es troba el feature, feature_id -> correspon a connec/guilly_id). volem seleccionar nomes aquells elements que pertanyen al nostre subGraph. els links estan associat a un node/edge del nostre subGraph per geometry y exit_id (exit_id -> arc/node_id del nostre subGraph). \n",
    "\n",
    "      partim de tres llistes:\n",
    "                                                                      \n",
    "                                                                      --  feautre_type -> connec/guilly (in list) \n",
    "            link [link_id, feature_type, feature_id, exit_id, row]    --  feature_id -> coonec/guilly_id\n",
    "                                                                      --  exit_id -> node/arc_id  (subGraph)\n",
    "\n",
    "            connec [connec_id, link_id, row]\n",
    "\n",
    "            guilly [guilly_id, link_id, row]\n",
    "\n",
    "      hem de crear tres noves sub-llistes dels elements connectats al nostre SubGrap.\n",
    "\n",
    "            edges_link\n",
    "\n",
    "            nodes_connec\n",
    "\n",
    "            nodes_guilly  \n",
    "\n",
    "NOTA: connec son els desembocaments de les cases y edificis a la xarxa (conexions entre xarca interna de cada edifici y xarxa externa de la ciutat), crec que no tots han de ser sanitaris, alguns poden ser reculls de aigua pluvial del terrat (preguntar a nicole)\n",
    "\n",
    "NOTA: guilly son els embornals del carrer (arquetes) que recullen nomes (?) aigues pluvials.\n",
    "\n",
    "\n",
    "2. Per mantenir una xarxa topologicament consistent, un edge (link) no pot anar associat a un altre edge (arc) com node_2, caldria crear un altre node en la interseccio de l'arc que no suposaria cap benefici y augmentaria la complexitat del subGraph. farem el seguent:\n",
    "\n",
    "      els nostres nodes_connec, nodes_guillu han destar associats al SubGrap a traves de un edges_link direccionat a un node de la xarxa, no a un arc.\n",
    "\n",
    "      els edges_link que estan direccionats a un arc de la xarxa aniran redireccionats a un dels nodes asociats del corresponent arc (node_1 / node_2)\n",
    "                  \n",
    "      nota: No importa gaire si el edge_link va a node_1 o node_2 pero es podria fer per proximitat de geometry.\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. correccio mesures \n",
    "\n",
    "study geometry: Chamber, Outfall, Manhole, Juntion \n",
    "\n",
    "in nodes and arcs, check None's\n",
    "\n",
    " -top_elev \n",
    "\n",
    " -ymax\n",
    "\n",
    " -negative slope\n",
    "\n",
    " -afegir bombes\n",
    "\n",
    "aproximar errors en mesures: volums, mesures, geometries -> autocalibratge ?\n",
    "\n",
    "Canviar el tipus de node de la depuradora a outfall en el subGrap"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REVISAR A PARTIR D'AQUÍ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. extreure els nodes/branca de sobreiximent per construir xarxa en sec\n",
    "\n",
    "extreure tots els node_type=outfall i les seves branques precedents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#volem extreure els node outfall de sobreiximent i els seus predecesors del subGrap\n",
    "delete = [node for node, data in subGraph.nodes(data=True) if subGraph.out_degree(node) == 0 and node!=edar]\n",
    "while len(delete) != 0:\n",
    "    G.remove_nodes_from(delete)\n",
    "    delete = [node for node, data in subGraph.nodes(data=True) if subGraph.out_degree(node) == 0 and node!=edar]\n",
    "# nota: estem extraient els nodes direccionats com a desembocament del subGrap exceptuant la depuradora hauria de ser el mateix que els marcats com a outfall"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. check geometry: mesures in nodes and arcs, check Null's\n",
    "\n",
    " -top_elev \n",
    " -ymax\n",
    " -slope\n",
    " -bombes\n",
    "\n",
    " "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Selexionem nomes aquells Link entre el subGraph i els Connc\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13572, 73)\n",
      "(172, 3)\n",
      "(13400, 73)\n",
      "(13722, 88)\n",
      "(171, 3)\n",
      "(13551, 88)\n",
      "(23474, 18)\n",
      "(31, 18)\n",
      "(23443, 18)\n"
     ]
    }
   ],
   "source": [
    "# EXTRACT ORPHAN NODE\n",
    "node = gpd.read_file(\"node.gpkg\")\n",
    "node.head(2)  # Prints the first 5 rows of the loaded data to see what it looks like.\n",
    "print(node.shape)\n",
    "node_orphan = gpd.read_file(\"node_orphan.gpkg\")\n",
    "node_orphan.head(2)  # Prints the first 5 rows of the loaded data to see what it looks like.\n",
    "print(node_orphan.shape)\n",
    "difference = set(node['node_id']) - set(node_orphan['id'])\n",
    "node_not_orphan = node[node['node_id'].isin(list(difference))]\n",
    "print(node_not_orphan.shape)\n",
    "\n",
    "\n",
    "# EXTRACT ORPHAN ARC\n",
    "arc = gpd.read_file(\"arc.gpkg\")\n",
    "arc.head(2)  # Prints the first 5 rows of the loaded data to see what it looks like.\n",
    "print(arc.shape)\n",
    "arc_orphan = gpd.read_file(\"arc_orphan.gpkg\")\n",
    "arc_orphan.head(2)  # Prints the first 5 rows of the loaded data to see what it looks like.\n",
    "print(arc_orphan.shape)\n",
    "difference = set(arc['arc_id']) - set(arc_orphan['id'])\n",
    "arc_not_orphan = arc[arc['arc_id'].isin(list(difference))]\n",
    "print(arc_not_orphan.shape)\n",
    "\n",
    "\n",
    "# EXTRACT ORPHAN LINK\n",
    "\n",
    "#ERROR: must be done with link.gpkg extracted fom giswater project\n",
    "link = gpd.read_file(\"link.gpkg\")\n",
    "print(link.shape)\n",
    "link_orphan = link[link['exit_id'].isin(list(set(node_orphan['id']) and set(arc_orphan['id'])))]\n",
    "print(link_orphan.shape)\n",
    "difference = set(link['link_id']) - set(link_orphan['link_id'])\n",
    "link_not_orphan=link[link['link_id'].isin(list(difference))]\n",
    "print(link_not_orphan.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
